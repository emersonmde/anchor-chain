searchState.loadedDescShard("anchor_chain", 0, "Anchor Chain\nDefines errors types for Anchor Chain\nOccurs when failing to construct or invoke a model in …\nError when no response is returned from the LLM model.\nA link in a processing chain that connects one <code>Node</code> to …\nGeneric error calling a model.\nOccurs when failing to construct OpenAI prompts, messages …\nError when configuring or using OpenSearch.\nError that occurs when calling OpenSearch APIs.\nGeneric error that occurs when serializing or …\nError constructing or rendering Tera templates.\nProvides structures for creating and executing chains.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nContains generic message types that can be used with …\nContains nodes that are designed to work with various LLM …\nCreates a new <code>Link</code> connecting the specified nodes.\nThe next node or link in the chain.\nModule providing foundational structures for building …\nThe first node in the chain.\nVarious nodes that can be chained together to form an LLM …\nProvides a structure for processing input through multiple …\nProcesses the given input through the chain of nodes.\nThis module contains various nodes for working with Vector …\nRepresents a chain of nodes that can asynchronously …\nA builder for constructing a <code>Chain</code> of nodes.\nA builder for constructing a <code>Chain</code> of nodes using Link.\nFinalizes the construction of the chain, returning a <code>Chain</code> …\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nAdds the first node to the chain.\nAdds a new node to the chain, linking it to the previous …\nCreates a new <code>ChainBuilder</code> instance.\nCreates a new <code>Chain</code> from the provided initial link.\nAsynchronously processes the provided input through the …\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nModule for interfacing with Claude 3 via AWS Bedrock.\nDefines the interface for an embedding model that can …\nModule for interfacing with Ollama models via the Ollama …\nModule for integrating OpenAI models.\nA processor for integrating Claude 3 LLM processing within …\nRepresents a source of an image to be processed by Claude …\nRepresents a message to be sent to Claude 3, comprising …\nDefines the content of a message for Claude 3, …\nA vector of content items within the message.\nThe content type, e.g., “text”.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nConstructs a new <code>Claude3Bedrock</code> processor with the …\nProcesses the input through the Claude 3 model, returning …\nThe role of the message, e.g., “user”.\nAn image source, if applicable.\nThe actual text content, if applicable.\nDefines the interface for an embedding model that can …\nEmbeds the given input text and returns the resulting …\nStruct for interfacing with Ollama models via the Ollama …\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCreates a new Ollama instance with the specified model.\nCreates a new Ollama instance with the specified model and …\nProcesses the input through the Ollama model, returning …\nGPT-3.5 Turbo model\nGPT-3.5 Turbo Instruct model\nGPT-4 Turbo model\nRepresents a processor for sending and processing requests …\nNode for making requests to OpenAI embedding models.\nNode for making requests to OpenAI Instruct models.\nOpenAI model types supported by the <code>OpenAI</code> node\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nConstructs a GPT3.5 Turbo model with the specified system …\nConstructs a GPT3.5 Turbo Instruct model.\nConstructs a GPT4 Turbo model with the specified system …\nConstructs a new <code>OpenAI</code> node using the specified API key.\nConstructs a new <code>OpenAI</code> processor with a specified API key.\nSends the input to the OpenAI API and processes the …\nSends the input to the OpenAI API and processes the …\nSends the input to the OpenAI API and processes the …\nSends the prompt to the OpenAI model and processes the …\nThe input type for the node.\nA no-op node that passes input through unchanged.\nRepresents a node that can process an input to produce an …\nThe output type for the node.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCreates a new <code>NoOpNode</code>.\nAsynchronously processes the given input, returning the …\nReturns the input unchanged.\nA simple input logging node.\nModule for handling dynamic prompts in processing chains.\nA simple input logging node\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCreate a new Logger node with the given prefix.\nLog the input and pass it through unchanged.\nA processor for handling text prompts within a processing …\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCreates a new <code>Prompt</code> processor with the specified template.\nProcesses the input HashMap and returns the rendered …\nA node that processes input through multiple nodes in …\nReturns the argument unchanged.\nThe function to process the output of the nodes.\nCalls <code>U::from(self)</code>.\nCreates a new <code>ParallelNode</code> with the provided nodes and …\nThe nodes that will process the input in parallel.\nProcesses the given input through nodes in parallel.\nConverts a function into a <code>BoxFuture</code> that can be used in a …\nStructures for managing documents in vector databases.\nOpenSearch client builder module.\nA node for indexing documents into OpenSearch.\nOpenSearchRetriever is a Node that retrieves documents …\nA struct representing a collection of documents.\nDocument structure for serializing and deserializing when …\nReturns the argument unchanged.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCreate a new document with the given text.\nCreate a new document with the given text and embedding.\nCreate a new document with the given id and text.\nBuilder for creating OpenSearch clients with various …\nBuild an OpenSearch client with the specified connection …\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCreate a new <code>OpenSearchClientBuilder</code>.\nSet the connection type to an AWS OpenSearch connection …\nSet the connection type to an AWS OpenSearch serverless …\nSet the connection type to a local connection using the …\nSet the connection type to a local connection using the …\nA node for indexing documents into OpenSearch.\nCreates a vector index in OpenSearch with the specified …\nReturns the argument unchanged.\nAutomatically indexes a list of documents. It embeds the …\nCalls <code>U::from(self)</code>.\nCreates a new <code>OpenSearchIndexer</code> with the specified …\nIndexes a list of documents into OpenSearch.\nA Node that retrieves documents from OpenSearch based on …\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCreates a new OpenSearchRetrieverBuilder using default AWS …\nRetrieves the top k documents from OpenSearch that are …\nRetrieves the top k documents from OpenSearch that are …\nQueries OpenSearch for the top k documents that are most …")